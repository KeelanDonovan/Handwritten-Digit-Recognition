{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cf60c7f6",
      "metadata": {
        "id": "cf60c7f6"
      },
      "source": [
        "This notebook implements a CNN for image classification of handwritten digits from the MNIST dataset using PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "ae2f8b3a",
      "metadata": {
        "id": "ae2f8b3a"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "from  torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b6fc973",
      "metadata": {
        "id": "0b6fc973"
      },
      "source": [
        "1. Import the relevant training and testing data.\n",
        "\n",
        "The MNIST dataset consists of handwritten digits (0-9) and is commonly used for training various image processing systems. Each image is a 28x28 pixel grayscale image. The dataset was created from samples of handwritten digits by high school students and employees of the United States Census Bureau."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "f9ea1f87",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9ea1f87",
        "outputId": "b64e0d59-8297-4caf-979b-38276220ae98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor() \n",
            "\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor() \n",
            "\n",
            "Training Data Shape: torch.Size([60000, 28, 28])\n",
            "Test Data Shape: torch.Size([10000, 28, 28])\n",
            "Training Data Labels Shape: torch.Size([60000])\n",
            "Training Data Labels: tensor([5, 0, 4,  ..., 5, 6, 8])\n"
          ]
        }
      ],
      "source": [
        "train_data = datasets.MNIST(\n",
        "  root='data',\n",
        "  train=True,\n",
        "  transform=ToTensor(),\n",
        "  download=True\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "  root='data',\n",
        "  train=False,\n",
        "  transform=ToTensor(),\n",
        "  download=True\n",
        ")\n",
        "\n",
        "print(train_data, \"\\n\")\n",
        "\n",
        "print(test_data, \"\\n\")\n",
        "\n",
        "print(f\"Training Data Shape: {train_data.data.shape}\")\n",
        "print(f\"Test Data Shape: {test_data.data.shape}\")\n",
        "print(f\"Training Data Labels Shape: {train_data.targets.shape}\")\n",
        "print(f\"Training Data Labels: {train_data.targets}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c293e77",
      "metadata": {
        "id": "1c293e77"
      },
      "source": [
        "2. Create a DataLoader for the training and testing data to facilitate batch processing and shuffling of the data during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "8755ee66",
      "metadata": {
        "id": "8755ee66"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2dc5297",
      "metadata": {
        "id": "d2dc5297"
      },
      "source": [
        "3. Creating the CNN architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "e1a4d7a3",
      "metadata": {
        "id": "e1a4d7a3"
      },
      "outputs": [],
      "source": [
        "class DigitRecognitionCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DigitRecognitionCNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
        "    self.dropout1 = nn.Dropout2d(0.25)\n",
        "    self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "    self.dropout2 = nn.Dropout2d(0.25)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fully_connected1 = nn.Linear(16 * 7 * 7, 128)\n",
        "    self.dropout3 = nn.Dropout(0.5)\n",
        "    self.fully_connected2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = self.dropout1(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = self.dropout2(x)\n",
        "    x = self.flatten(x)\n",
        "    x = F.relu(self.fully_connected1(x))\n",
        "    x = self.dropout3(x)\n",
        "    x = self.fully_connected2(x)\n",
        "    return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c700ae07",
      "metadata": {
        "id": "c700ae07"
      },
      "source": [
        "4. Initialize the model, define the optimizer, loss function, and hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "ebdd3fa4",
      "metadata": {
        "id": "ebdd3fa4"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = DigitRecognitionCNN().to(device)\n",
        "\n",
        "learning_rate = 0.01\n",
        "batch_size = 64\n",
        "num_epochs = 25\n",
        "momentum = 0.9\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51987f69",
      "metadata": {
        "id": "51987f69"
      },
      "source": [
        "5. Define the training loop to train the model over multiple epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "715933c5",
      "metadata": {
        "id": "715933c5"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch % 20 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18019f3a",
      "metadata": {
        "id": "18019f3a"
      },
      "source": [
        "6. Define the test_loop to evaluate the model's performance on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "46c69472",
      "metadata": {
        "id": "46c69472"
      },
      "outputs": [],
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "  model.eval()\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "          X, y = X.to(device), y.to(device)\n",
        "          pred = model(X)\n",
        "\n",
        "          test_loss += loss_fn(pred, y).item()\n",
        "          correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b342aa13",
      "metadata": {
        "id": "b342aa13"
      },
      "source": [
        "7. Training the model and evaluating its performance on the test dataset after each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "c53ed1d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c53ed1d0",
        "outputId": "9b1b7c7d-67e2-422e-c219-778e5cc4c15d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.291801  [   64/60000]\n",
            "loss: 2.289010  [ 1344/60000]\n",
            "loss: 2.281850  [ 2624/60000]\n",
            "loss: 2.138399  [ 3904/60000]\n",
            "loss: 1.690030  [ 5184/60000]\n",
            "loss: 1.270763  [ 6464/60000]\n",
            "loss: 0.964486  [ 7744/60000]\n",
            "loss: 0.938643  [ 9024/60000]\n",
            "loss: 0.964367  [10304/60000]\n",
            "loss: 0.847934  [11584/60000]\n",
            "loss: 0.657844  [12864/60000]\n",
            "loss: 0.637684  [14144/60000]\n",
            "loss: 0.671048  [15424/60000]\n",
            "loss: 0.541622  [16704/60000]\n",
            "loss: 0.520491  [17984/60000]\n",
            "loss: 0.801283  [19264/60000]\n",
            "loss: 0.554509  [20544/60000]\n",
            "loss: 0.346801  [21824/60000]\n",
            "loss: 0.463713  [23104/60000]\n",
            "loss: 0.382089  [24384/60000]\n",
            "loss: 0.442530  [25664/60000]\n",
            "loss: 0.361729  [26944/60000]\n",
            "loss: 0.281048  [28224/60000]\n",
            "loss: 0.279772  [29504/60000]\n",
            "loss: 0.690418  [30784/60000]\n",
            "loss: 0.282774  [32064/60000]\n",
            "loss: 0.204539  [33344/60000]\n",
            "loss: 0.224191  [34624/60000]\n",
            "loss: 0.202340  [35904/60000]\n",
            "loss: 0.339478  [37184/60000]\n",
            "loss: 0.428717  [38464/60000]\n",
            "loss: 0.355361  [39744/60000]\n",
            "loss: 0.187306  [41024/60000]\n",
            "loss: 0.592618  [42304/60000]\n",
            "loss: 0.290720  [43584/60000]\n",
            "loss: 0.285754  [44864/60000]\n",
            "loss: 0.474074  [46144/60000]\n",
            "loss: 0.425466  [47424/60000]\n",
            "loss: 0.360827  [48704/60000]\n",
            "loss: 0.270283  [49984/60000]\n",
            "loss: 0.306907  [51264/60000]\n",
            "loss: 0.334350  [52544/60000]\n",
            "loss: 0.326416  [53824/60000]\n",
            "loss: 0.115159  [55104/60000]\n",
            "loss: 0.166803  [56384/60000]\n",
            "loss: 0.327996  [57664/60000]\n",
            "loss: 0.261101  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.1%, Avg loss: 0.116852 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.251978  [   64/60000]\n",
            "loss: 0.399782  [ 1344/60000]\n",
            "loss: 0.290822  [ 2624/60000]\n",
            "loss: 0.293696  [ 3904/60000]\n",
            "loss: 0.179726  [ 5184/60000]\n",
            "loss: 0.277572  [ 6464/60000]\n",
            "loss: 0.367309  [ 7744/60000]\n",
            "loss: 0.214338  [ 9024/60000]\n",
            "loss: 0.266838  [10304/60000]\n",
            "loss: 0.258783  [11584/60000]\n",
            "loss: 0.165670  [12864/60000]\n",
            "loss: 0.505708  [14144/60000]\n",
            "loss: 0.183118  [15424/60000]\n",
            "loss: 0.100425  [16704/60000]\n",
            "loss: 0.186712  [17984/60000]\n",
            "loss: 0.270677  [19264/60000]\n",
            "loss: 0.224470  [20544/60000]\n",
            "loss: 0.235272  [21824/60000]\n",
            "loss: 0.118912  [23104/60000]\n",
            "loss: 0.096958  [24384/60000]\n",
            "loss: 0.221464  [25664/60000]\n",
            "loss: 0.371356  [26944/60000]\n",
            "loss: 0.215359  [28224/60000]\n",
            "loss: 0.093295  [29504/60000]\n",
            "loss: 0.393633  [30784/60000]\n",
            "loss: 0.233105  [32064/60000]\n",
            "loss: 0.142756  [33344/60000]\n",
            "loss: 0.367118  [34624/60000]\n",
            "loss: 0.090041  [35904/60000]\n",
            "loss: 0.175047  [37184/60000]\n",
            "loss: 0.439352  [38464/60000]\n",
            "loss: 0.240546  [39744/60000]\n",
            "loss: 0.133290  [41024/60000]\n",
            "loss: 0.290189  [42304/60000]\n",
            "loss: 0.181726  [43584/60000]\n",
            "loss: 0.154806  [44864/60000]\n",
            "loss: 0.198202  [46144/60000]\n",
            "loss: 0.193510  [47424/60000]\n",
            "loss: 0.143348  [48704/60000]\n",
            "loss: 0.278541  [49984/60000]\n",
            "loss: 0.174820  [51264/60000]\n",
            "loss: 0.051207  [52544/60000]\n",
            "loss: 0.200376  [53824/60000]\n",
            "loss: 0.145451  [55104/60000]\n",
            "loss: 0.110665  [56384/60000]\n",
            "loss: 0.137641  [57664/60000]\n",
            "loss: 0.217131  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.3%, Avg loss: 0.078922 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.180634  [   64/60000]\n",
            "loss: 0.116118  [ 1344/60000]\n",
            "loss: 0.137029  [ 2624/60000]\n",
            "loss: 0.170933  [ 3904/60000]\n",
            "loss: 0.131617  [ 5184/60000]\n",
            "loss: 0.157129  [ 6464/60000]\n",
            "loss: 0.147382  [ 7744/60000]\n",
            "loss: 0.264618  [ 9024/60000]\n",
            "loss: 0.079920  [10304/60000]\n",
            "loss: 0.097325  [11584/60000]\n",
            "loss: 0.186982  [12864/60000]\n",
            "loss: 0.288046  [14144/60000]\n",
            "loss: 0.105995  [15424/60000]\n",
            "loss: 0.076161  [16704/60000]\n",
            "loss: 0.174421  [17984/60000]\n",
            "loss: 0.190387  [19264/60000]\n",
            "loss: 0.164145  [20544/60000]\n",
            "loss: 0.157045  [21824/60000]\n",
            "loss: 0.166565  [23104/60000]\n",
            "loss: 0.169754  [24384/60000]\n",
            "loss: 0.109789  [25664/60000]\n",
            "loss: 0.088482  [26944/60000]\n",
            "loss: 0.085236  [28224/60000]\n",
            "loss: 0.396800  [29504/60000]\n",
            "loss: 0.148753  [30784/60000]\n",
            "loss: 0.215092  [32064/60000]\n",
            "loss: 0.321949  [33344/60000]\n",
            "loss: 0.110005  [34624/60000]\n",
            "loss: 0.193553  [35904/60000]\n",
            "loss: 0.178498  [37184/60000]\n",
            "loss: 0.089871  [38464/60000]\n",
            "loss: 0.258152  [39744/60000]\n",
            "loss: 0.435514  [41024/60000]\n",
            "loss: 0.232794  [42304/60000]\n",
            "loss: 0.269166  [43584/60000]\n",
            "loss: 0.041781  [44864/60000]\n",
            "loss: 0.111197  [46144/60000]\n",
            "loss: 0.146478  [47424/60000]\n",
            "loss: 0.107930  [48704/60000]\n",
            "loss: 0.224096  [49984/60000]\n",
            "loss: 0.064091  [51264/60000]\n",
            "loss: 0.269325  [52544/60000]\n",
            "loss: 0.074924  [53824/60000]\n",
            "loss: 0.227740  [55104/60000]\n",
            "loss: 0.131718  [56384/60000]\n",
            "loss: 0.194246  [57664/60000]\n",
            "loss: 0.195148  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.9%, Avg loss: 0.063629 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.145618  [   64/60000]\n",
            "loss: 0.149072  [ 1344/60000]\n",
            "loss: 0.096132  [ 2624/60000]\n",
            "loss: 0.057080  [ 3904/60000]\n",
            "loss: 0.118711  [ 5184/60000]\n",
            "loss: 0.190393  [ 6464/60000]\n",
            "loss: 0.269788  [ 7744/60000]\n",
            "loss: 0.216229  [ 9024/60000]\n",
            "loss: 0.108418  [10304/60000]\n",
            "loss: 0.205127  [11584/60000]\n",
            "loss: 0.229172  [12864/60000]\n",
            "loss: 0.225346  [14144/60000]\n",
            "loss: 0.095511  [15424/60000]\n",
            "loss: 0.034170  [16704/60000]\n",
            "loss: 0.224418  [17984/60000]\n",
            "loss: 0.088430  [19264/60000]\n",
            "loss: 0.189333  [20544/60000]\n",
            "loss: 0.060192  [21824/60000]\n",
            "loss: 0.326146  [23104/60000]\n",
            "loss: 0.039450  [24384/60000]\n",
            "loss: 0.081804  [25664/60000]\n",
            "loss: 0.051016  [26944/60000]\n",
            "loss: 0.047129  [28224/60000]\n",
            "loss: 0.110077  [29504/60000]\n",
            "loss: 0.097003  [30784/60000]\n",
            "loss: 0.101459  [32064/60000]\n",
            "loss: 0.138671  [33344/60000]\n",
            "loss: 0.077520  [34624/60000]\n",
            "loss: 0.024237  [35904/60000]\n",
            "loss: 0.056537  [37184/60000]\n",
            "loss: 0.104898  [38464/60000]\n",
            "loss: 0.063659  [39744/60000]\n",
            "loss: 0.187497  [41024/60000]\n",
            "loss: 0.318653  [42304/60000]\n",
            "loss: 0.138717  [43584/60000]\n",
            "loss: 0.094919  [44864/60000]\n",
            "loss: 0.304595  [46144/60000]\n",
            "loss: 0.087147  [47424/60000]\n",
            "loss: 0.277447  [48704/60000]\n",
            "loss: 0.136528  [49984/60000]\n",
            "loss: 0.179457  [51264/60000]\n",
            "loss: 0.216761  [52544/60000]\n",
            "loss: 0.072529  [53824/60000]\n",
            "loss: 0.077700  [55104/60000]\n",
            "loss: 0.313667  [56384/60000]\n",
            "loss: 0.016702  [57664/60000]\n",
            "loss: 0.039332  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.054666 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.114530  [   64/60000]\n",
            "loss: 0.136975  [ 1344/60000]\n",
            "loss: 0.033272  [ 2624/60000]\n",
            "loss: 0.067253  [ 3904/60000]\n",
            "loss: 0.044950  [ 5184/60000]\n",
            "loss: 0.092559  [ 6464/60000]\n",
            "loss: 0.155621  [ 7744/60000]\n",
            "loss: 0.024438  [ 9024/60000]\n",
            "loss: 0.304511  [10304/60000]\n",
            "loss: 0.117597  [11584/60000]\n",
            "loss: 0.165691  [12864/60000]\n",
            "loss: 0.045230  [14144/60000]\n",
            "loss: 0.095425  [15424/60000]\n",
            "loss: 0.048788  [16704/60000]\n",
            "loss: 0.146291  [17984/60000]\n",
            "loss: 0.140219  [19264/60000]\n",
            "loss: 0.115872  [20544/60000]\n",
            "loss: 0.017954  [21824/60000]\n",
            "loss: 0.054363  [23104/60000]\n",
            "loss: 0.127744  [24384/60000]\n",
            "loss: 0.072060  [25664/60000]\n",
            "loss: 0.126304  [26944/60000]\n",
            "loss: 0.020360  [28224/60000]\n",
            "loss: 0.012628  [29504/60000]\n",
            "loss: 0.094828  [30784/60000]\n",
            "loss: 0.040478  [32064/60000]\n",
            "loss: 0.127127  [33344/60000]\n",
            "loss: 0.166710  [34624/60000]\n",
            "loss: 0.084314  [35904/60000]\n",
            "loss: 0.080131  [37184/60000]\n",
            "loss: 0.300464  [38464/60000]\n",
            "loss: 0.048818  [39744/60000]\n",
            "loss: 0.055603  [41024/60000]\n",
            "loss: 0.134807  [42304/60000]\n",
            "loss: 0.086181  [43584/60000]\n",
            "loss: 0.155297  [44864/60000]\n",
            "loss: 0.044015  [46144/60000]\n",
            "loss: 0.077396  [47424/60000]\n",
            "loss: 0.030470  [48704/60000]\n",
            "loss: 0.081107  [49984/60000]\n",
            "loss: 0.049743  [51264/60000]\n",
            "loss: 0.551410  [52544/60000]\n",
            "loss: 0.038945  [53824/60000]\n",
            "loss: 0.094366  [55104/60000]\n",
            "loss: 0.305523  [56384/60000]\n",
            "loss: 0.111152  [57664/60000]\n",
            "loss: 0.224193  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.3%, Avg loss: 0.050271 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.204787  [   64/60000]\n",
            "loss: 0.100636  [ 1344/60000]\n",
            "loss: 0.136852  [ 2624/60000]\n",
            "loss: 0.087483  [ 3904/60000]\n",
            "loss: 0.206246  [ 5184/60000]\n",
            "loss: 0.143313  [ 6464/60000]\n",
            "loss: 0.074877  [ 7744/60000]\n",
            "loss: 0.091236  [ 9024/60000]\n",
            "loss: 0.050078  [10304/60000]\n",
            "loss: 0.094935  [11584/60000]\n",
            "loss: 0.093071  [12864/60000]\n",
            "loss: 0.264423  [14144/60000]\n",
            "loss: 0.104091  [15424/60000]\n",
            "loss: 0.091687  [16704/60000]\n",
            "loss: 0.049189  [17984/60000]\n",
            "loss: 0.107970  [19264/60000]\n",
            "loss: 0.055663  [20544/60000]\n",
            "loss: 0.075616  [21824/60000]\n",
            "loss: 0.045349  [23104/60000]\n",
            "loss: 0.118726  [24384/60000]\n",
            "loss: 0.196536  [25664/60000]\n",
            "loss: 0.160551  [26944/60000]\n",
            "loss: 0.043865  [28224/60000]\n",
            "loss: 0.087541  [29504/60000]\n",
            "loss: 0.065817  [30784/60000]\n",
            "loss: 0.033984  [32064/60000]\n",
            "loss: 0.150750  [33344/60000]\n",
            "loss: 0.046535  [34624/60000]\n",
            "loss: 0.232755  [35904/60000]\n",
            "loss: 0.098736  [37184/60000]\n",
            "loss: 0.126462  [38464/60000]\n",
            "loss: 0.215289  [39744/60000]\n",
            "loss: 0.163228  [41024/60000]\n",
            "loss: 0.034332  [42304/60000]\n",
            "loss: 0.115382  [43584/60000]\n",
            "loss: 0.107338  [44864/60000]\n",
            "loss: 0.155073  [46144/60000]\n",
            "loss: 0.101298  [47424/60000]\n",
            "loss: 0.202136  [48704/60000]\n",
            "loss: 0.105921  [49984/60000]\n",
            "loss: 0.084688  [51264/60000]\n",
            "loss: 0.018670  [52544/60000]\n",
            "loss: 0.064318  [53824/60000]\n",
            "loss: 0.293379  [55104/60000]\n",
            "loss: 0.232594  [56384/60000]\n",
            "loss: 0.084298  [57664/60000]\n",
            "loss: 0.174561  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.4%, Avg loss: 0.047853 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.017219  [   64/60000]\n",
            "loss: 0.051062  [ 1344/60000]\n",
            "loss: 0.052206  [ 2624/60000]\n",
            "loss: 0.086405  [ 3904/60000]\n",
            "loss: 0.084555  [ 5184/60000]\n",
            "loss: 0.069152  [ 6464/60000]\n",
            "loss: 0.097331  [ 7744/60000]\n",
            "loss: 0.037454  [ 9024/60000]\n",
            "loss: 0.173573  [10304/60000]\n",
            "loss: 0.068358  [11584/60000]\n",
            "loss: 0.099141  [12864/60000]\n",
            "loss: 0.118592  [14144/60000]\n",
            "loss: 0.062018  [15424/60000]\n",
            "loss: 0.144960  [16704/60000]\n",
            "loss: 0.048133  [17984/60000]\n",
            "loss: 0.114337  [19264/60000]\n",
            "loss: 0.268913  [20544/60000]\n",
            "loss: 0.076745  [21824/60000]\n",
            "loss: 0.073088  [23104/60000]\n",
            "loss: 0.067215  [24384/60000]\n",
            "loss: 0.027354  [25664/60000]\n",
            "loss: 0.052385  [26944/60000]\n",
            "loss: 0.177119  [28224/60000]\n",
            "loss: 0.252623  [29504/60000]\n",
            "loss: 0.072711  [30784/60000]\n",
            "loss: 0.011825  [32064/60000]\n",
            "loss: 0.133266  [33344/60000]\n",
            "loss: 0.129521  [34624/60000]\n",
            "loss: 0.080402  [35904/60000]\n",
            "loss: 0.072603  [37184/60000]\n",
            "loss: 0.076629  [38464/60000]\n",
            "loss: 0.092267  [39744/60000]\n",
            "loss: 0.078707  [41024/60000]\n",
            "loss: 0.092202  [42304/60000]\n",
            "loss: 0.058870  [43584/60000]\n",
            "loss: 0.077153  [44864/60000]\n",
            "loss: 0.154233  [46144/60000]\n",
            "loss: 0.068864  [47424/60000]\n",
            "loss: 0.066520  [48704/60000]\n",
            "loss: 0.058240  [49984/60000]\n",
            "loss: 0.025924  [51264/60000]\n",
            "loss: 0.230568  [52544/60000]\n",
            "loss: 0.070140  [53824/60000]\n",
            "loss: 0.051893  [55104/60000]\n",
            "loss: 0.126785  [56384/60000]\n",
            "loss: 0.062711  [57664/60000]\n",
            "loss: 0.012050  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.5%, Avg loss: 0.044244 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.067415  [   64/60000]\n",
            "loss: 0.027223  [ 1344/60000]\n",
            "loss: 0.135833  [ 2624/60000]\n",
            "loss: 0.074683  [ 3904/60000]\n",
            "loss: 0.099710  [ 5184/60000]\n",
            "loss: 0.095449  [ 6464/60000]\n",
            "loss: 0.114240  [ 7744/60000]\n",
            "loss: 0.217343  [ 9024/60000]\n",
            "loss: 0.014282  [10304/60000]\n",
            "loss: 0.115537  [11584/60000]\n",
            "loss: 0.235240  [12864/60000]\n",
            "loss: 0.089986  [14144/60000]\n",
            "loss: 0.031140  [15424/60000]\n",
            "loss: 0.114094  [16704/60000]\n",
            "loss: 0.041667  [17984/60000]\n",
            "loss: 0.059564  [19264/60000]\n",
            "loss: 0.078265  [20544/60000]\n",
            "loss: 0.297618  [21824/60000]\n",
            "loss: 0.073739  [23104/60000]\n",
            "loss: 0.170492  [24384/60000]\n",
            "loss: 0.173378  [25664/60000]\n",
            "loss: 0.069185  [26944/60000]\n",
            "loss: 0.162098  [28224/60000]\n",
            "loss: 0.126677  [29504/60000]\n",
            "loss: 0.149302  [30784/60000]\n",
            "loss: 0.286935  [32064/60000]\n",
            "loss: 0.150839  [33344/60000]\n",
            "loss: 0.072460  [34624/60000]\n",
            "loss: 0.146405  [35904/60000]\n",
            "loss: 0.152541  [37184/60000]\n",
            "loss: 0.076540  [38464/60000]\n",
            "loss: 0.232806  [39744/60000]\n",
            "loss: 0.287571  [41024/60000]\n",
            "loss: 0.029638  [42304/60000]\n",
            "loss: 0.068982  [43584/60000]\n",
            "loss: 0.078598  [44864/60000]\n",
            "loss: 0.041442  [46144/60000]\n",
            "loss: 0.133966  [47424/60000]\n",
            "loss: 0.041742  [48704/60000]\n",
            "loss: 0.044949  [49984/60000]\n",
            "loss: 0.394156  [51264/60000]\n",
            "loss: 0.051347  [52544/60000]\n",
            "loss: 0.072711  [53824/60000]\n",
            "loss: 0.087411  [55104/60000]\n",
            "loss: 0.025191  [56384/60000]\n",
            "loss: 0.177152  [57664/60000]\n",
            "loss: 0.067890  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.6%, Avg loss: 0.040974 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.094635  [   64/60000]\n",
            "loss: 0.149920  [ 1344/60000]\n",
            "loss: 0.040648  [ 2624/60000]\n",
            "loss: 0.010046  [ 3904/60000]\n",
            "loss: 0.039993  [ 5184/60000]\n",
            "loss: 0.363872  [ 6464/60000]\n",
            "loss: 0.022051  [ 7744/60000]\n",
            "loss: 0.260097  [ 9024/60000]\n",
            "loss: 0.173306  [10304/60000]\n",
            "loss: 0.028288  [11584/60000]\n",
            "loss: 0.167249  [12864/60000]\n",
            "loss: 0.207304  [14144/60000]\n",
            "loss: 0.036158  [15424/60000]\n",
            "loss: 0.123825  [16704/60000]\n",
            "loss: 0.028649  [17984/60000]\n",
            "loss: 0.074790  [19264/60000]\n",
            "loss: 0.047991  [20544/60000]\n",
            "loss: 0.113675  [21824/60000]\n",
            "loss: 0.053455  [23104/60000]\n",
            "loss: 0.115288  [24384/60000]\n",
            "loss: 0.034551  [25664/60000]\n",
            "loss: 0.162697  [26944/60000]\n",
            "loss: 0.107985  [28224/60000]\n",
            "loss: 0.052875  [29504/60000]\n",
            "loss: 0.029623  [30784/60000]\n",
            "loss: 0.044275  [32064/60000]\n",
            "loss: 0.077999  [33344/60000]\n",
            "loss: 0.078594  [34624/60000]\n",
            "loss: 0.071553  [35904/60000]\n",
            "loss: 0.086646  [37184/60000]\n",
            "loss: 0.094512  [38464/60000]\n",
            "loss: 0.152659  [39744/60000]\n",
            "loss: 0.055244  [41024/60000]\n",
            "loss: 0.036829  [42304/60000]\n",
            "loss: 0.144045  [43584/60000]\n",
            "loss: 0.158948  [44864/60000]\n",
            "loss: 0.158382  [46144/60000]\n",
            "loss: 0.049287  [47424/60000]\n",
            "loss: 0.133249  [48704/60000]\n",
            "loss: 0.103904  [49984/60000]\n",
            "loss: 0.035246  [51264/60000]\n",
            "loss: 0.044325  [52544/60000]\n",
            "loss: 0.170703  [53824/60000]\n",
            "loss: 0.019933  [55104/60000]\n",
            "loss: 0.088594  [56384/60000]\n",
            "loss: 0.088128  [57664/60000]\n",
            "loss: 0.125449  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.8%, Avg loss: 0.036820 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.069021  [   64/60000]\n",
            "loss: 0.103160  [ 1344/60000]\n",
            "loss: 0.059161  [ 2624/60000]\n",
            "loss: 0.067518  [ 3904/60000]\n",
            "loss: 0.159203  [ 5184/60000]\n",
            "loss: 0.016376  [ 6464/60000]\n",
            "loss: 0.072000  [ 7744/60000]\n",
            "loss: 0.099265  [ 9024/60000]\n",
            "loss: 0.077804  [10304/60000]\n",
            "loss: 0.052416  [11584/60000]\n",
            "loss: 0.104298  [12864/60000]\n",
            "loss: 0.077190  [14144/60000]\n",
            "loss: 0.060865  [15424/60000]\n",
            "loss: 0.081876  [16704/60000]\n",
            "loss: 0.056400  [17984/60000]\n",
            "loss: 0.161461  [19264/60000]\n",
            "loss: 0.087778  [20544/60000]\n",
            "loss: 0.084916  [21824/60000]\n",
            "loss: 0.022363  [23104/60000]\n",
            "loss: 0.055910  [24384/60000]\n",
            "loss: 0.197186  [25664/60000]\n",
            "loss: 0.031102  [26944/60000]\n",
            "loss: 0.023603  [28224/60000]\n",
            "loss: 0.052964  [29504/60000]\n",
            "loss: 0.114989  [30784/60000]\n",
            "loss: 0.110896  [32064/60000]\n",
            "loss: 0.054147  [33344/60000]\n",
            "loss: 0.056368  [34624/60000]\n",
            "loss: 0.118039  [35904/60000]\n",
            "loss: 0.062268  [37184/60000]\n",
            "loss: 0.003208  [38464/60000]\n",
            "loss: 0.089569  [39744/60000]\n",
            "loss: 0.084808  [41024/60000]\n",
            "loss: 0.024874  [42304/60000]\n",
            "loss: 0.037708  [43584/60000]\n",
            "loss: 0.042343  [44864/60000]\n",
            "loss: 0.060640  [46144/60000]\n",
            "loss: 0.045183  [47424/60000]\n",
            "loss: 0.053082  [48704/60000]\n",
            "loss: 0.013927  [49984/60000]\n",
            "loss: 0.110380  [51264/60000]\n",
            "loss: 0.013845  [52544/60000]\n",
            "loss: 0.184940  [53824/60000]\n",
            "loss: 0.106001  [55104/60000]\n",
            "loss: 0.162926  [56384/60000]\n",
            "loss: 0.072160  [57664/60000]\n",
            "loss: 0.225864  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.7%, Avg loss: 0.037690 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.122089  [   64/60000]\n",
            "loss: 0.052158  [ 1344/60000]\n",
            "loss: 0.078468  [ 2624/60000]\n",
            "loss: 0.214281  [ 3904/60000]\n",
            "loss: 0.166691  [ 5184/60000]\n",
            "loss: 0.067662  [ 6464/60000]\n",
            "loss: 0.037582  [ 7744/60000]\n",
            "loss: 0.011659  [ 9024/60000]\n",
            "loss: 0.026218  [10304/60000]\n",
            "loss: 0.237720  [11584/60000]\n",
            "loss: 0.122220  [12864/60000]\n",
            "loss: 0.058991  [14144/60000]\n",
            "loss: 0.099800  [15424/60000]\n",
            "loss: 0.086722  [16704/60000]\n",
            "loss: 0.036602  [17984/60000]\n",
            "loss: 0.192320  [19264/60000]\n",
            "loss: 0.080538  [20544/60000]\n",
            "loss: 0.068394  [21824/60000]\n",
            "loss: 0.028458  [23104/60000]\n",
            "loss: 0.083214  [24384/60000]\n",
            "loss: 0.065277  [25664/60000]\n",
            "loss: 0.047269  [26944/60000]\n",
            "loss: 0.081533  [28224/60000]\n",
            "loss: 0.031113  [29504/60000]\n",
            "loss: 0.231843  [30784/60000]\n",
            "loss: 0.130102  [32064/60000]\n",
            "loss: 0.145424  [33344/60000]\n",
            "loss: 0.117909  [34624/60000]\n",
            "loss: 0.065902  [35904/60000]\n",
            "loss: 0.109939  [37184/60000]\n",
            "loss: 0.015322  [38464/60000]\n",
            "loss: 0.047184  [39744/60000]\n",
            "loss: 0.050563  [41024/60000]\n",
            "loss: 0.040879  [42304/60000]\n",
            "loss: 0.015152  [43584/60000]\n",
            "loss: 0.031477  [44864/60000]\n",
            "loss: 0.173531  [46144/60000]\n",
            "loss: 0.103575  [47424/60000]\n",
            "loss: 0.095635  [48704/60000]\n",
            "loss: 0.110047  [49984/60000]\n",
            "loss: 0.130995  [51264/60000]\n",
            "loss: 0.153786  [52544/60000]\n",
            "loss: 0.012075  [53824/60000]\n",
            "loss: 0.092217  [55104/60000]\n",
            "loss: 0.087294  [56384/60000]\n",
            "loss: 0.044072  [57664/60000]\n",
            "loss: 0.074346  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.8%, Avg loss: 0.035525 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.049585  [   64/60000]\n",
            "loss: 0.041484  [ 1344/60000]\n",
            "loss: 0.099378  [ 2624/60000]\n",
            "loss: 0.168270  [ 3904/60000]\n",
            "loss: 0.115264  [ 5184/60000]\n",
            "loss: 0.182612  [ 6464/60000]\n",
            "loss: 0.086184  [ 7744/60000]\n",
            "loss: 0.072860  [ 9024/60000]\n",
            "loss: 0.183462  [10304/60000]\n",
            "loss: 0.046183  [11584/60000]\n",
            "loss: 0.019807  [12864/60000]\n",
            "loss: 0.041486  [14144/60000]\n",
            "loss: 0.114248  [15424/60000]\n",
            "loss: 0.065472  [16704/60000]\n",
            "loss: 0.138729  [17984/60000]\n",
            "loss: 0.075493  [19264/60000]\n",
            "loss: 0.036357  [20544/60000]\n",
            "loss: 0.013447  [21824/60000]\n",
            "loss: 0.162255  [23104/60000]\n",
            "loss: 0.088938  [24384/60000]\n",
            "loss: 0.140115  [25664/60000]\n",
            "loss: 0.096763  [26944/60000]\n",
            "loss: 0.071267  [28224/60000]\n",
            "loss: 0.074606  [29504/60000]\n",
            "loss: 0.139867  [30784/60000]\n",
            "loss: 0.050488  [32064/60000]\n",
            "loss: 0.103980  [33344/60000]\n",
            "loss: 0.112701  [34624/60000]\n",
            "loss: 0.145927  [35904/60000]\n",
            "loss: 0.182815  [37184/60000]\n",
            "loss: 0.030443  [38464/60000]\n",
            "loss: 0.050885  [39744/60000]\n",
            "loss: 0.470604  [41024/60000]\n",
            "loss: 0.024946  [42304/60000]\n",
            "loss: 0.032638  [43584/60000]\n",
            "loss: 0.152031  [44864/60000]\n",
            "loss: 0.097187  [46144/60000]\n",
            "loss: 0.093149  [47424/60000]\n",
            "loss: 0.085853  [48704/60000]\n",
            "loss: 0.015330  [49984/60000]\n",
            "loss: 0.117052  [51264/60000]\n",
            "loss: 0.047997  [52544/60000]\n",
            "loss: 0.077117  [53824/60000]\n",
            "loss: 0.193240  [55104/60000]\n",
            "loss: 0.105020  [56384/60000]\n",
            "loss: 0.122552  [57664/60000]\n",
            "loss: 0.078605  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.8%, Avg loss: 0.033529 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.150072  [   64/60000]\n",
            "loss: 0.063256  [ 1344/60000]\n",
            "loss: 0.030051  [ 2624/60000]\n",
            "loss: 0.030045  [ 3904/60000]\n",
            "loss: 0.066117  [ 5184/60000]\n",
            "loss: 0.075948  [ 6464/60000]\n",
            "loss: 0.005036  [ 7744/60000]\n",
            "loss: 0.110376  [ 9024/60000]\n",
            "loss: 0.056636  [10304/60000]\n",
            "loss: 0.030729  [11584/60000]\n",
            "loss: 0.091814  [12864/60000]\n",
            "loss: 0.028544  [14144/60000]\n",
            "loss: 0.138855  [15424/60000]\n",
            "loss: 0.023466  [16704/60000]\n",
            "loss: 0.221107  [17984/60000]\n",
            "loss: 0.008744  [19264/60000]\n",
            "loss: 0.192405  [20544/60000]\n",
            "loss: 0.008976  [21824/60000]\n",
            "loss: 0.091002  [23104/60000]\n",
            "loss: 0.125443  [24384/60000]\n",
            "loss: 0.030182  [25664/60000]\n",
            "loss: 0.121258  [26944/60000]\n",
            "loss: 0.108860  [28224/60000]\n",
            "loss: 0.116602  [29504/60000]\n",
            "loss: 0.039582  [30784/60000]\n",
            "loss: 0.167691  [32064/60000]\n",
            "loss: 0.127380  [33344/60000]\n",
            "loss: 0.072784  [34624/60000]\n",
            "loss: 0.110013  [35904/60000]\n",
            "loss: 0.054423  [37184/60000]\n",
            "loss: 0.031904  [38464/60000]\n",
            "loss: 0.053216  [39744/60000]\n",
            "loss: 0.099972  [41024/60000]\n",
            "loss: 0.033435  [42304/60000]\n",
            "loss: 0.026375  [43584/60000]\n",
            "loss: 0.083848  [44864/60000]\n",
            "loss: 0.040385  [46144/60000]\n",
            "loss: 0.030585  [47424/60000]\n",
            "loss: 0.067206  [48704/60000]\n",
            "loss: 0.016919  [49984/60000]\n",
            "loss: 0.034652  [51264/60000]\n",
            "loss: 0.171724  [52544/60000]\n",
            "loss: 0.095181  [53824/60000]\n",
            "loss: 0.103033  [55104/60000]\n",
            "loss: 0.018270  [56384/60000]\n",
            "loss: 0.029012  [57664/60000]\n",
            "loss: 0.060034  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.7%, Avg loss: 0.035237 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.043301  [   64/60000]\n",
            "loss: 0.209110  [ 1344/60000]\n",
            "loss: 0.031689  [ 2624/60000]\n",
            "loss: 0.214826  [ 3904/60000]\n",
            "loss: 0.031481  [ 5184/60000]\n",
            "loss: 0.090821  [ 6464/60000]\n",
            "loss: 0.255947  [ 7744/60000]\n",
            "loss: 0.032045  [ 9024/60000]\n",
            "loss: 0.052498  [10304/60000]\n",
            "loss: 0.112628  [11584/60000]\n",
            "loss: 0.038191  [12864/60000]\n",
            "loss: 0.161140  [14144/60000]\n",
            "loss: 0.247581  [15424/60000]\n",
            "loss: 0.012058  [16704/60000]\n",
            "loss: 0.077178  [17984/60000]\n",
            "loss: 0.141201  [19264/60000]\n",
            "loss: 0.039451  [20544/60000]\n",
            "loss: 0.082046  [21824/60000]\n",
            "loss: 0.019183  [23104/60000]\n",
            "loss: 0.003407  [24384/60000]\n",
            "loss: 0.055898  [25664/60000]\n",
            "loss: 0.025996  [26944/60000]\n",
            "loss: 0.132191  [28224/60000]\n",
            "loss: 0.045917  [29504/60000]\n",
            "loss: 0.103546  [30784/60000]\n",
            "loss: 0.071496  [32064/60000]\n",
            "loss: 0.040314  [33344/60000]\n",
            "loss: 0.041543  [34624/60000]\n",
            "loss: 0.013632  [35904/60000]\n",
            "loss: 0.041919  [37184/60000]\n",
            "loss: 0.012626  [38464/60000]\n",
            "loss: 0.057444  [39744/60000]\n",
            "loss: 0.079065  [41024/60000]\n",
            "loss: 0.089966  [42304/60000]\n",
            "loss: 0.011130  [43584/60000]\n",
            "loss: 0.050513  [44864/60000]\n",
            "loss: 0.032682  [46144/60000]\n",
            "loss: 0.167826  [47424/60000]\n",
            "loss: 0.066196  [48704/60000]\n",
            "loss: 0.126178  [49984/60000]\n",
            "loss: 0.025044  [51264/60000]\n",
            "loss: 0.105320  [52544/60000]\n",
            "loss: 0.018199  [53824/60000]\n",
            "loss: 0.076638  [55104/60000]\n",
            "loss: 0.098526  [56384/60000]\n",
            "loss: 0.094175  [57664/60000]\n",
            "loss: 0.045904  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.7%, Avg loss: 0.034950 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.058134  [   64/60000]\n",
            "loss: 0.162795  [ 1344/60000]\n",
            "loss: 0.011836  [ 2624/60000]\n",
            "loss: 0.023311  [ 3904/60000]\n",
            "loss: 0.029232  [ 5184/60000]\n",
            "loss: 0.069772  [ 6464/60000]\n",
            "loss: 0.065530  [ 7744/60000]\n",
            "loss: 0.096469  [ 9024/60000]\n",
            "loss: 0.187446  [10304/60000]\n",
            "loss: 0.235317  [11584/60000]\n",
            "loss: 0.089756  [12864/60000]\n",
            "loss: 0.034818  [14144/60000]\n",
            "loss: 0.039832  [15424/60000]\n",
            "loss: 0.027917  [16704/60000]\n",
            "loss: 0.083695  [17984/60000]\n",
            "loss: 0.030209  [19264/60000]\n",
            "loss: 0.035748  [20544/60000]\n",
            "loss: 0.167494  [21824/60000]\n",
            "loss: 0.021843  [23104/60000]\n",
            "loss: 0.080865  [24384/60000]\n",
            "loss: 0.049997  [25664/60000]\n",
            "loss: 0.092585  [26944/60000]\n",
            "loss: 0.090448  [28224/60000]\n",
            "loss: 0.029998  [29504/60000]\n",
            "loss: 0.019018  [30784/60000]\n",
            "loss: 0.137982  [32064/60000]\n",
            "loss: 0.017360  [33344/60000]\n",
            "loss: 0.068774  [34624/60000]\n",
            "loss: 0.034238  [35904/60000]\n",
            "loss: 0.065626  [37184/60000]\n",
            "loss: 0.086274  [38464/60000]\n",
            "loss: 0.094560  [39744/60000]\n",
            "loss: 0.022314  [41024/60000]\n",
            "loss: 0.067278  [42304/60000]\n",
            "loss: 0.045849  [43584/60000]\n",
            "loss: 0.064397  [44864/60000]\n",
            "loss: 0.039686  [46144/60000]\n",
            "loss: 0.050514  [47424/60000]\n",
            "loss: 0.027568  [48704/60000]\n",
            "loss: 0.062731  [49984/60000]\n",
            "loss: 0.092047  [51264/60000]\n",
            "loss: 0.034875  [52544/60000]\n",
            "loss: 0.065971  [53824/60000]\n",
            "loss: 0.024183  [55104/60000]\n",
            "loss: 0.047366  [56384/60000]\n",
            "loss: 0.042192  [57664/60000]\n",
            "loss: 0.049624  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.8%, Avg loss: 0.032329 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.009984  [   64/60000]\n",
            "loss: 0.022793  [ 1344/60000]\n",
            "loss: 0.114875  [ 2624/60000]\n",
            "loss: 0.026441  [ 3904/60000]\n",
            "loss: 0.077855  [ 5184/60000]\n",
            "loss: 0.006915  [ 6464/60000]\n",
            "loss: 0.163926  [ 7744/60000]\n",
            "loss: 0.012603  [ 9024/60000]\n",
            "loss: 0.207344  [10304/60000]\n",
            "loss: 0.032941  [11584/60000]\n",
            "loss: 0.130766  [12864/60000]\n",
            "loss: 0.025505  [14144/60000]\n",
            "loss: 0.204351  [15424/60000]\n",
            "loss: 0.084904  [16704/60000]\n",
            "loss: 0.045655  [17984/60000]\n",
            "loss: 0.025948  [19264/60000]\n",
            "loss: 0.037308  [20544/60000]\n",
            "loss: 0.045852  [21824/60000]\n",
            "loss: 0.025887  [23104/60000]\n",
            "loss: 0.055708  [24384/60000]\n",
            "loss: 0.066212  [25664/60000]\n",
            "loss: 0.041994  [26944/60000]\n",
            "loss: 0.056012  [28224/60000]\n",
            "loss: 0.057496  [29504/60000]\n",
            "loss: 0.046225  [30784/60000]\n",
            "loss: 0.067109  [32064/60000]\n",
            "loss: 0.092919  [33344/60000]\n",
            "loss: 0.024692  [34624/60000]\n",
            "loss: 0.139860  [35904/60000]\n",
            "loss: 0.127894  [37184/60000]\n",
            "loss: 0.022321  [38464/60000]\n",
            "loss: 0.061534  [39744/60000]\n",
            "loss: 0.042734  [41024/60000]\n",
            "loss: 0.008056  [42304/60000]\n",
            "loss: 0.032944  [43584/60000]\n",
            "loss: 0.077167  [44864/60000]\n",
            "loss: 0.080842  [46144/60000]\n",
            "loss: 0.043254  [47424/60000]\n",
            "loss: 0.005027  [48704/60000]\n",
            "loss: 0.030348  [49984/60000]\n",
            "loss: 0.201136  [51264/60000]\n",
            "loss: 0.063184  [52544/60000]\n",
            "loss: 0.077684  [53824/60000]\n",
            "loss: 0.133961  [55104/60000]\n",
            "loss: 0.051281  [56384/60000]\n",
            "loss: 0.032464  [57664/60000]\n",
            "loss: 0.175074  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 0.030957 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.120185  [   64/60000]\n",
            "loss: 0.009618  [ 1344/60000]\n",
            "loss: 0.040431  [ 2624/60000]\n",
            "loss: 0.009909  [ 3904/60000]\n",
            "loss: 0.047457  [ 5184/60000]\n",
            "loss: 0.070140  [ 6464/60000]\n",
            "loss: 0.066451  [ 7744/60000]\n",
            "loss: 0.085349  [ 9024/60000]\n",
            "loss: 0.006783  [10304/60000]\n",
            "loss: 0.042653  [11584/60000]\n",
            "loss: 0.064338  [12864/60000]\n",
            "loss: 0.018162  [14144/60000]\n",
            "loss: 0.106706  [15424/60000]\n",
            "loss: 0.048678  [16704/60000]\n",
            "loss: 0.114112  [17984/60000]\n",
            "loss: 0.097434  [19264/60000]\n",
            "loss: 0.064548  [20544/60000]\n",
            "loss: 0.063745  [21824/60000]\n",
            "loss: 0.093803  [23104/60000]\n",
            "loss: 0.165453  [24384/60000]\n",
            "loss: 0.044704  [25664/60000]\n",
            "loss: 0.014083  [26944/60000]\n",
            "loss: 0.037337  [28224/60000]\n",
            "loss: 0.041053  [29504/60000]\n",
            "loss: 0.107854  [30784/60000]\n",
            "loss: 0.060035  [32064/60000]\n",
            "loss: 0.011664  [33344/60000]\n",
            "loss: 0.022274  [34624/60000]\n",
            "loss: 0.035411  [35904/60000]\n",
            "loss: 0.091286  [37184/60000]\n",
            "loss: 0.063352  [38464/60000]\n",
            "loss: 0.030486  [39744/60000]\n",
            "loss: 0.008900  [41024/60000]\n",
            "loss: 0.089571  [42304/60000]\n",
            "loss: 0.152692  [43584/60000]\n",
            "loss: 0.011907  [44864/60000]\n",
            "loss: 0.073533  [46144/60000]\n",
            "loss: 0.041244  [47424/60000]\n",
            "loss: 0.147246  [48704/60000]\n",
            "loss: 0.010682  [49984/60000]\n",
            "loss: 0.121924  [51264/60000]\n",
            "loss: 0.102848  [52544/60000]\n",
            "loss: 0.078216  [53824/60000]\n",
            "loss: 0.394932  [55104/60000]\n",
            "loss: 0.050537  [56384/60000]\n",
            "loss: 0.040868  [57664/60000]\n",
            "loss: 0.062077  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.8%, Avg loss: 0.032113 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.044414  [   64/60000]\n",
            "loss: 0.170078  [ 1344/60000]\n",
            "loss: 0.043695  [ 2624/60000]\n",
            "loss: 0.047142  [ 3904/60000]\n",
            "loss: 0.109777  [ 5184/60000]\n",
            "loss: 0.110524  [ 6464/60000]\n",
            "loss: 0.017056  [ 7744/60000]\n",
            "loss: 0.085455  [ 9024/60000]\n",
            "loss: 0.079272  [10304/60000]\n",
            "loss: 0.054303  [11584/60000]\n",
            "loss: 0.070039  [12864/60000]\n",
            "loss: 0.140859  [14144/60000]\n",
            "loss: 0.075893  [15424/60000]\n",
            "loss: 0.069725  [16704/60000]\n",
            "loss: 0.064405  [17984/60000]\n",
            "loss: 0.050754  [19264/60000]\n",
            "loss: 0.041755  [20544/60000]\n",
            "loss: 0.077719  [21824/60000]\n",
            "loss: 0.071610  [23104/60000]\n",
            "loss: 0.051892  [24384/60000]\n",
            "loss: 0.054242  [25664/60000]\n",
            "loss: 0.079267  [26944/60000]\n",
            "loss: 0.046018  [28224/60000]\n",
            "loss: 0.053202  [29504/60000]\n",
            "loss: 0.046560  [30784/60000]\n",
            "loss: 0.070174  [32064/60000]\n",
            "loss: 0.015888  [33344/60000]\n",
            "loss: 0.101232  [34624/60000]\n",
            "loss: 0.048980  [35904/60000]\n",
            "loss: 0.031443  [37184/60000]\n",
            "loss: 0.151348  [38464/60000]\n",
            "loss: 0.090605  [39744/60000]\n",
            "loss: 0.011985  [41024/60000]\n",
            "loss: 0.149761  [42304/60000]\n",
            "loss: 0.184163  [43584/60000]\n",
            "loss: 0.050615  [44864/60000]\n",
            "loss: 0.042190  [46144/60000]\n",
            "loss: 0.332082  [47424/60000]\n",
            "loss: 0.097486  [48704/60000]\n",
            "loss: 0.036848  [49984/60000]\n",
            "loss: 0.012212  [51264/60000]\n",
            "loss: 0.034213  [52544/60000]\n",
            "loss: 0.013248  [53824/60000]\n",
            "loss: 0.101151  [55104/60000]\n",
            "loss: 0.075448  [56384/60000]\n",
            "loss: 0.063969  [57664/60000]\n",
            "loss: 0.009448  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 0.030719 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.015579  [   64/60000]\n",
            "loss: 0.026258  [ 1344/60000]\n",
            "loss: 0.044412  [ 2624/60000]\n",
            "loss: 0.127005  [ 3904/60000]\n",
            "loss: 0.170041  [ 5184/60000]\n",
            "loss: 0.055703  [ 6464/60000]\n",
            "loss: 0.036420  [ 7744/60000]\n",
            "loss: 0.051989  [ 9024/60000]\n",
            "loss: 0.150649  [10304/60000]\n",
            "loss: 0.080701  [11584/60000]\n",
            "loss: 0.026124  [12864/60000]\n",
            "loss: 0.106759  [14144/60000]\n",
            "loss: 0.024661  [15424/60000]\n",
            "loss: 0.041195  [16704/60000]\n",
            "loss: 0.021704  [17984/60000]\n",
            "loss: 0.036572  [19264/60000]\n",
            "loss: 0.201258  [20544/60000]\n",
            "loss: 0.031445  [21824/60000]\n",
            "loss: 0.129945  [23104/60000]\n",
            "loss: 0.067098  [24384/60000]\n",
            "loss: 0.093013  [25664/60000]\n",
            "loss: 0.044044  [26944/60000]\n",
            "loss: 0.035641  [28224/60000]\n",
            "loss: 0.034923  [29504/60000]\n",
            "loss: 0.110079  [30784/60000]\n",
            "loss: 0.048094  [32064/60000]\n",
            "loss: 0.228757  [33344/60000]\n",
            "loss: 0.057534  [34624/60000]\n",
            "loss: 0.014505  [35904/60000]\n",
            "loss: 0.048468  [37184/60000]\n",
            "loss: 0.011491  [38464/60000]\n",
            "loss: 0.065602  [39744/60000]\n",
            "loss: 0.033150  [41024/60000]\n",
            "loss: 0.073424  [42304/60000]\n",
            "loss: 0.071875  [43584/60000]\n",
            "loss: 0.161112  [44864/60000]\n",
            "loss: 0.067693  [46144/60000]\n",
            "loss: 0.112174  [47424/60000]\n",
            "loss: 0.024061  [48704/60000]\n",
            "loss: 0.068080  [49984/60000]\n",
            "loss: 0.167649  [51264/60000]\n",
            "loss: 0.026834  [52544/60000]\n",
            "loss: 0.071895  [53824/60000]\n",
            "loss: 0.062543  [55104/60000]\n",
            "loss: 0.032193  [56384/60000]\n",
            "loss: 0.009605  [57664/60000]\n",
            "loss: 0.013402  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 0.027788 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.067550  [   64/60000]\n",
            "loss: 0.038361  [ 1344/60000]\n",
            "loss: 0.060286  [ 2624/60000]\n",
            "loss: 0.020197  [ 3904/60000]\n",
            "loss: 0.121411  [ 5184/60000]\n",
            "loss: 0.040065  [ 6464/60000]\n",
            "loss: 0.063096  [ 7744/60000]\n",
            "loss: 0.011960  [ 9024/60000]\n",
            "loss: 0.073742  [10304/60000]\n",
            "loss: 0.008816  [11584/60000]\n",
            "loss: 0.094988  [12864/60000]\n",
            "loss: 0.023183  [14144/60000]\n",
            "loss: 0.026024  [15424/60000]\n",
            "loss: 0.062251  [16704/60000]\n",
            "loss: 0.073534  [17984/60000]\n",
            "loss: 0.025872  [19264/60000]\n",
            "loss: 0.019754  [20544/60000]\n",
            "loss: 0.008710  [21824/60000]\n",
            "loss: 0.209158  [23104/60000]\n",
            "loss: 0.122189  [24384/60000]\n",
            "loss: 0.034734  [25664/60000]\n",
            "loss: 0.142175  [26944/60000]\n",
            "loss: 0.116568  [28224/60000]\n",
            "loss: 0.036012  [29504/60000]\n",
            "loss: 0.082357  [30784/60000]\n",
            "loss: 0.029613  [32064/60000]\n",
            "loss: 0.032801  [33344/60000]\n",
            "loss: 0.049436  [34624/60000]\n",
            "loss: 0.036895  [35904/60000]\n",
            "loss: 0.018354  [37184/60000]\n",
            "loss: 0.013950  [38464/60000]\n",
            "loss: 0.104294  [39744/60000]\n",
            "loss: 0.068701  [41024/60000]\n",
            "loss: 0.197411  [42304/60000]\n",
            "loss: 0.217796  [43584/60000]\n",
            "loss: 0.056787  [44864/60000]\n",
            "loss: 0.051341  [46144/60000]\n",
            "loss: 0.164812  [47424/60000]\n",
            "loss: 0.024199  [48704/60000]\n",
            "loss: 0.055931  [49984/60000]\n",
            "loss: 0.101404  [51264/60000]\n",
            "loss: 0.009251  [52544/60000]\n",
            "loss: 0.082035  [53824/60000]\n",
            "loss: 0.086585  [55104/60000]\n",
            "loss: 0.008064  [56384/60000]\n",
            "loss: 0.098346  [57664/60000]\n",
            "loss: 0.010072  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 0.030402 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.004485  [   64/60000]\n",
            "loss: 0.005700  [ 1344/60000]\n",
            "loss: 0.043943  [ 2624/60000]\n",
            "loss: 0.031407  [ 3904/60000]\n",
            "loss: 0.078832  [ 5184/60000]\n",
            "loss: 0.041233  [ 6464/60000]\n",
            "loss: 0.082392  [ 7744/60000]\n",
            "loss: 0.070941  [ 9024/60000]\n",
            "loss: 0.058165  [10304/60000]\n",
            "loss: 0.061744  [11584/60000]\n",
            "loss: 0.167999  [12864/60000]\n",
            "loss: 0.281900  [14144/60000]\n",
            "loss: 0.064763  [15424/60000]\n",
            "loss: 0.124549  [16704/60000]\n",
            "loss: 0.109750  [17984/60000]\n",
            "loss: 0.107625  [19264/60000]\n",
            "loss: 0.376915  [20544/60000]\n",
            "loss: 0.011602  [21824/60000]\n",
            "loss: 0.014988  [23104/60000]\n",
            "loss: 0.004592  [24384/60000]\n",
            "loss: 0.011863  [25664/60000]\n",
            "loss: 0.107035  [26944/60000]\n",
            "loss: 0.304736  [28224/60000]\n",
            "loss: 0.137635  [29504/60000]\n",
            "loss: 0.021883  [30784/60000]\n",
            "loss: 0.085277  [32064/60000]\n",
            "loss: 0.061596  [33344/60000]\n",
            "loss: 0.103337  [34624/60000]\n",
            "loss: 0.094335  [35904/60000]\n",
            "loss: 0.029573  [37184/60000]\n",
            "loss: 0.092019  [38464/60000]\n",
            "loss: 0.168224  [39744/60000]\n",
            "loss: 0.199788  [41024/60000]\n",
            "loss: 0.005216  [42304/60000]\n",
            "loss: 0.186507  [43584/60000]\n",
            "loss: 0.022276  [44864/60000]\n",
            "loss: 0.070759  [46144/60000]\n",
            "loss: 0.037074  [47424/60000]\n",
            "loss: 0.025848  [48704/60000]\n",
            "loss: 0.118543  [49984/60000]\n",
            "loss: 0.018826  [51264/60000]\n",
            "loss: 0.032547  [52544/60000]\n",
            "loss: 0.146131  [53824/60000]\n",
            "loss: 0.268840  [55104/60000]\n",
            "loss: 0.038479  [56384/60000]\n",
            "loss: 0.057469  [57664/60000]\n",
            "loss: 0.051437  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 0.030832 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.039307  [   64/60000]\n",
            "loss: 0.058313  [ 1344/60000]\n",
            "loss: 0.083484  [ 2624/60000]\n",
            "loss: 0.141589  [ 3904/60000]\n",
            "loss: 0.031953  [ 5184/60000]\n",
            "loss: 0.012264  [ 6464/60000]\n",
            "loss: 0.011609  [ 7744/60000]\n",
            "loss: 0.022057  [ 9024/60000]\n",
            "loss: 0.098935  [10304/60000]\n",
            "loss: 0.063539  [11584/60000]\n",
            "loss: 0.003960  [12864/60000]\n",
            "loss: 0.048626  [14144/60000]\n",
            "loss: 0.085464  [15424/60000]\n",
            "loss: 0.060348  [16704/60000]\n",
            "loss: 0.175968  [17984/60000]\n",
            "loss: 0.020938  [19264/60000]\n",
            "loss: 0.055719  [20544/60000]\n",
            "loss: 0.043688  [21824/60000]\n",
            "loss: 0.049810  [23104/60000]\n",
            "loss: 0.155816  [24384/60000]\n",
            "loss: 0.077118  [25664/60000]\n",
            "loss: 0.048889  [26944/60000]\n",
            "loss: 0.022006  [28224/60000]\n",
            "loss: 0.112938  [29504/60000]\n",
            "loss: 0.021576  [30784/60000]\n",
            "loss: 0.121440  [32064/60000]\n",
            "loss: 0.058283  [33344/60000]\n",
            "loss: 0.049579  [34624/60000]\n",
            "loss: 0.119655  [35904/60000]\n",
            "loss: 0.026886  [37184/60000]\n",
            "loss: 0.088098  [38464/60000]\n",
            "loss: 0.016766  [39744/60000]\n",
            "loss: 0.185314  [41024/60000]\n",
            "loss: 0.053778  [42304/60000]\n",
            "loss: 0.168387  [43584/60000]\n",
            "loss: 0.127000  [44864/60000]\n",
            "loss: 0.041400  [46144/60000]\n",
            "loss: 0.279190  [47424/60000]\n",
            "loss: 0.025390  [48704/60000]\n",
            "loss: 0.031569  [49984/60000]\n",
            "loss: 0.190504  [51264/60000]\n",
            "loss: 0.039998  [52544/60000]\n",
            "loss: 0.146032  [53824/60000]\n",
            "loss: 0.080840  [55104/60000]\n",
            "loss: 0.083677  [56384/60000]\n",
            "loss: 0.099258  [57664/60000]\n",
            "loss: 0.046922  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 0.026726 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.029322  [   64/60000]\n",
            "loss: 0.008488  [ 1344/60000]\n",
            "loss: 0.015286  [ 2624/60000]\n",
            "loss: 0.039404  [ 3904/60000]\n",
            "loss: 0.006785  [ 5184/60000]\n",
            "loss: 0.022356  [ 6464/60000]\n",
            "loss: 0.131838  [ 7744/60000]\n",
            "loss: 0.067823  [ 9024/60000]\n",
            "loss: 0.065563  [10304/60000]\n",
            "loss: 0.030767  [11584/60000]\n",
            "loss: 0.110755  [12864/60000]\n",
            "loss: 0.235205  [14144/60000]\n",
            "loss: 0.073708  [15424/60000]\n",
            "loss: 0.056369  [16704/60000]\n",
            "loss: 0.061752  [17984/60000]\n",
            "loss: 0.217990  [19264/60000]\n",
            "loss: 0.139723  [20544/60000]\n",
            "loss: 0.025194  [21824/60000]\n",
            "loss: 0.053736  [23104/60000]\n",
            "loss: 0.012254  [24384/60000]\n",
            "loss: 0.055323  [25664/60000]\n",
            "loss: 0.036187  [26944/60000]\n",
            "loss: 0.008045  [28224/60000]\n",
            "loss: 0.216065  [29504/60000]\n",
            "loss: 0.123994  [30784/60000]\n",
            "loss: 0.050470  [32064/60000]\n",
            "loss: 0.037956  [33344/60000]\n",
            "loss: 0.008237  [34624/60000]\n",
            "loss: 0.161255  [35904/60000]\n",
            "loss: 0.041010  [37184/60000]\n",
            "loss: 0.035623  [38464/60000]\n",
            "loss: 0.034354  [39744/60000]\n",
            "loss: 0.085508  [41024/60000]\n",
            "loss: 0.079242  [42304/60000]\n",
            "loss: 0.116826  [43584/60000]\n",
            "loss: 0.084901  [44864/60000]\n",
            "loss: 0.025895  [46144/60000]\n",
            "loss: 0.185108  [47424/60000]\n",
            "loss: 0.178371  [48704/60000]\n",
            "loss: 0.063042  [49984/60000]\n",
            "loss: 0.078034  [51264/60000]\n",
            "loss: 0.032719  [52544/60000]\n",
            "loss: 0.057118  [53824/60000]\n",
            "loss: 0.038786  [55104/60000]\n",
            "loss: 0.021793  [56384/60000]\n",
            "loss: 0.048699  [57664/60000]\n",
            "loss: 0.082547  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 0.027403 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.006218  [   64/60000]\n",
            "loss: 0.084980  [ 1344/60000]\n",
            "loss: 0.012830  [ 2624/60000]\n",
            "loss: 0.070224  [ 3904/60000]\n",
            "loss: 0.039700  [ 5184/60000]\n",
            "loss: 0.024880  [ 6464/60000]\n",
            "loss: 0.015861  [ 7744/60000]\n",
            "loss: 0.043796  [ 9024/60000]\n",
            "loss: 0.051102  [10304/60000]\n",
            "loss: 0.062910  [11584/60000]\n",
            "loss: 0.018165  [12864/60000]\n",
            "loss: 0.035497  [14144/60000]\n",
            "loss: 0.117298  [15424/60000]\n",
            "loss: 0.090875  [16704/60000]\n",
            "loss: 0.059747  [17984/60000]\n",
            "loss: 0.042838  [19264/60000]\n",
            "loss: 0.083855  [20544/60000]\n",
            "loss: 0.086142  [21824/60000]\n",
            "loss: 0.060107  [23104/60000]\n",
            "loss: 0.017642  [24384/60000]\n",
            "loss: 0.181747  [25664/60000]\n",
            "loss: 0.003694  [26944/60000]\n",
            "loss: 0.090162  [28224/60000]\n",
            "loss: 0.030856  [29504/60000]\n",
            "loss: 0.010801  [30784/60000]\n",
            "loss: 0.056584  [32064/60000]\n",
            "loss: 0.100158  [33344/60000]\n",
            "loss: 0.085888  [34624/60000]\n",
            "loss: 0.125784  [35904/60000]\n",
            "loss: 0.016975  [37184/60000]\n",
            "loss: 0.085365  [38464/60000]\n",
            "loss: 0.098387  [39744/60000]\n",
            "loss: 0.100980  [41024/60000]\n",
            "loss: 0.011308  [42304/60000]\n",
            "loss: 0.023705  [43584/60000]\n",
            "loss: 0.141471  [44864/60000]\n",
            "loss: 0.040142  [46144/60000]\n",
            "loss: 0.156841  [47424/60000]\n",
            "loss: 0.030463  [48704/60000]\n",
            "loss: 0.127171  [49984/60000]\n",
            "loss: 0.084579  [51264/60000]\n",
            "loss: 0.191288  [52544/60000]\n",
            "loss: 0.060389  [53824/60000]\n",
            "loss: 0.039072  [55104/60000]\n",
            "loss: 0.057874  [56384/60000]\n",
            "loss: 0.087631  [57664/60000]\n",
            "loss: 0.014505  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 0.029010 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.037001  [   64/60000]\n",
            "loss: 0.008135  [ 1344/60000]\n",
            "loss: 0.075185  [ 2624/60000]\n",
            "loss: 0.131231  [ 3904/60000]\n",
            "loss: 0.015979  [ 5184/60000]\n",
            "loss: 0.084714  [ 6464/60000]\n",
            "loss: 0.058052  [ 7744/60000]\n",
            "loss: 0.130272  [ 9024/60000]\n",
            "loss: 0.075528  [10304/60000]\n",
            "loss: 0.008087  [11584/60000]\n",
            "loss: 0.012710  [12864/60000]\n",
            "loss: 0.055815  [14144/60000]\n",
            "loss: 0.012261  [15424/60000]\n",
            "loss: 0.133211  [16704/60000]\n",
            "loss: 0.115967  [17984/60000]\n",
            "loss: 0.062554  [19264/60000]\n",
            "loss: 0.079545  [20544/60000]\n",
            "loss: 0.048722  [21824/60000]\n",
            "loss: 0.024137  [23104/60000]\n",
            "loss: 0.054393  [24384/60000]\n",
            "loss: 0.020957  [25664/60000]\n",
            "loss: 0.007428  [26944/60000]\n",
            "loss: 0.224686  [28224/60000]\n",
            "loss: 0.012889  [29504/60000]\n",
            "loss: 0.071255  [30784/60000]\n",
            "loss: 0.029535  [32064/60000]\n",
            "loss: 0.035271  [33344/60000]\n",
            "loss: 0.106834  [34624/60000]\n",
            "loss: 0.007953  [35904/60000]\n",
            "loss: 0.051777  [37184/60000]\n",
            "loss: 0.081825  [38464/60000]\n",
            "loss: 0.106310  [39744/60000]\n",
            "loss: 0.005052  [41024/60000]\n",
            "loss: 0.085765  [42304/60000]\n",
            "loss: 0.056310  [43584/60000]\n",
            "loss: 0.012969  [44864/60000]\n",
            "loss: 0.110287  [46144/60000]\n",
            "loss: 0.053013  [47424/60000]\n",
            "loss: 0.042550  [48704/60000]\n",
            "loss: 0.124666  [49984/60000]\n",
            "loss: 0.041335  [51264/60000]\n",
            "loss: 0.093853  [52544/60000]\n",
            "loss: 0.043993  [53824/60000]\n",
            "loss: 0.083421  [55104/60000]\n",
            "loss: 0.021453  [56384/60000]\n",
            "loss: 0.088299  [57664/60000]\n",
            "loss: 0.092272  [58944/60000]\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 0.027818 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    train_loop(train_loader, model, loss_fn, optimizer)\n",
        "    test_loop(test_loader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62b23576",
      "metadata": {
        "id": "62b23576"
      },
      "source": [
        "8. Save the trained model to a file for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "ab31e60b",
      "metadata": {
        "id": "ab31e60b"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), \"digit_recog_cnn.pt\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}