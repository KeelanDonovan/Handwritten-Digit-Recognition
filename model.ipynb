{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf60c7f6",
   "metadata": {},
   "source": [
    "This notebook implements a CNN for image classification of handwritten digits from the MNIST dataset using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ae2f8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from  torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6fc973",
   "metadata": {},
   "source": [
    "1. Import the relevant training and testing data. \n",
    "\n",
    "The MNIST dataset consists of handwritten digits (0-9) and is commonly used for training various image processing systems. Each image is a 28x28 pixel grayscale image. The dataset was created from samples of handwritten digits by high school students and employees of the United States Census Bureau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f9ea1f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor() \n",
      "\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor() \n",
      "\n",
      "Training Data Shape: torch.Size([60000, 28, 28])\n",
      "Test Data Shape: torch.Size([10000, 28, 28])\n",
      "Training Data Labels Shape: torch.Size([60000])\n",
      "Training Data Labels: tensor([5, 0, 4,  ..., 5, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(\n",
    "  root='data',\n",
    "  train=True,\n",
    "  transform=ToTensor(),\n",
    "  download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "  root='data',\n",
    "  train=False,\n",
    "  transform=ToTensor(),\n",
    "  download=True\n",
    ")\n",
    "\n",
    "print(train_data, \"\\n\")\n",
    "\n",
    "print(test_data, \"\\n\")\n",
    "\n",
    "print(f\"Training Data Shape: {train_data.data.shape}\")\n",
    "print(f\"Test Data Shape: {test_data.data.shape}\")\n",
    "print(f\"Training Data Labels Shape: {train_data.targets.shape}\")\n",
    "print(f\"Training Data Labels: {train_data.targets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c293e77",
   "metadata": {},
   "source": [
    "2. Create a DataLoader for the training and testing data to facilitate batch processing and shuffling of the data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8755ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dc5297",
   "metadata": {},
   "source": [
    "3. Creating the CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e1a4d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitRecognitionCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(DigitRecognitionCNN, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "    self.fully_connected1 = nn.Linear(32 * 3 * 3, 10)\n",
    "    self.flatten = nn.Flatten()\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.conv1(x))\n",
    "    x = F.max_pool2d(x, 2)\n",
    "    x = F.relu(self.conv2(x))\n",
    "    x = F.max_pool2d(x, 2)\n",
    "    x = F.relu(self.conv3(x))\n",
    "    x = F.max_pool2d(x, 2)\n",
    "    x = self.flatten(x)\n",
    "    x = self.fully_connected1(x)\n",
    "    return F.log_softmax(x, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c700ae07",
   "metadata": {},
   "source": [
    "4. Initialize the model, define the optimizer, loss function, and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ebdd3fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DigitRecognitionCNN().to(device)\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "momentum = 0.9\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=momentum)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51987f69",
   "metadata": {},
   "source": [
    "5. Define the training loop to train the model over multiple epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "715933c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "  size = len(dataloader.dataset)\n",
    "  model.train()\n",
    "  \n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    \n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if batch % 20 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18019f3a",
   "metadata": {},
   "source": [
    "6. Define the test_loop to evaluate the model's performance on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "46c69472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "  model.eval()\n",
    "  size = len(dataloader.dataset)\n",
    "  num_batches = len(dataloader)\n",
    "  test_loss, correct = 0, 0\n",
    "  \n",
    "  with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "  test_loss /= num_batches\n",
    "  correct /= size\n",
    "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b342aa13",
   "metadata": {},
   "source": [
    "7. Training the model and evaluating its performance on the test dataset after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c53ed1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.281793  [   64/60000]\n",
      "loss: 2.297732  [ 1344/60000]\n",
      "loss: 2.280181  [ 2624/60000]\n",
      "loss: 2.241024  [ 3904/60000]\n",
      "loss: 2.049153  [ 5184/60000]\n",
      "loss: 0.920866  [ 6464/60000]\n",
      "loss: 0.747428  [ 7744/60000]\n",
      "loss: 0.485872  [ 9024/60000]\n",
      "loss: 0.261962  [10304/60000]\n",
      "loss: 0.369763  [11584/60000]\n",
      "loss: 0.410188  [12864/60000]\n",
      "loss: 0.310647  [14144/60000]\n",
      "loss: 0.288551  [15424/60000]\n",
      "loss: 0.159185  [16704/60000]\n",
      "loss: 0.100998  [17984/60000]\n",
      "loss: 0.324333  [19264/60000]\n",
      "loss: 0.265818  [20544/60000]\n",
      "loss: 0.212542  [21824/60000]\n",
      "loss: 0.223787  [23104/60000]\n",
      "loss: 0.194866  [24384/60000]\n",
      "loss: 0.303805  [25664/60000]\n",
      "loss: 0.083204  [26944/60000]\n",
      "loss: 0.151929  [28224/60000]\n",
      "loss: 0.170409  [29504/60000]\n",
      "loss: 0.224617  [30784/60000]\n",
      "loss: 0.076335  [32064/60000]\n",
      "loss: 0.178564  [33344/60000]\n",
      "loss: 0.140453  [34624/60000]\n",
      "loss: 0.227343  [35904/60000]\n",
      "loss: 0.134882  [37184/60000]\n",
      "loss: 0.075737  [38464/60000]\n",
      "loss: 0.048108  [39744/60000]\n",
      "loss: 0.105362  [41024/60000]\n",
      "loss: 0.203427  [42304/60000]\n",
      "loss: 0.186095  [43584/60000]\n",
      "loss: 0.291957  [44864/60000]\n",
      "loss: 0.038764  [46144/60000]\n",
      "loss: 0.131953  [47424/60000]\n",
      "loss: 0.173462  [48704/60000]\n",
      "loss: 0.050429  [49984/60000]\n",
      "loss: 0.077888  [51264/60000]\n",
      "loss: 0.105390  [52544/60000]\n",
      "loss: 0.086956  [53824/60000]\n",
      "loss: 0.094637  [55104/60000]\n",
      "loss: 0.100732  [56384/60000]\n",
      "loss: 0.206130  [57664/60000]\n",
      "loss: 0.089683  [58944/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.080095 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.040249  [   64/60000]\n",
      "loss: 0.110616  [ 1344/60000]\n",
      "loss: 0.042090  [ 2624/60000]\n",
      "loss: 0.014071  [ 3904/60000]\n",
      "loss: 0.102330  [ 5184/60000]\n",
      "loss: 0.129598  [ 6464/60000]\n",
      "loss: 0.297934  [ 7744/60000]\n",
      "loss: 0.088649  [ 9024/60000]\n",
      "loss: 0.095588  [10304/60000]\n",
      "loss: 0.179598  [11584/60000]\n",
      "loss: 0.175296  [12864/60000]\n",
      "loss: 0.050740  [14144/60000]\n",
      "loss: 0.058516  [15424/60000]\n",
      "loss: 0.059059  [16704/60000]\n",
      "loss: 0.027596  [17984/60000]\n",
      "loss: 0.022782  [19264/60000]\n",
      "loss: 0.074463  [20544/60000]\n",
      "loss: 0.035016  [21824/60000]\n",
      "loss: 0.137399  [23104/60000]\n",
      "loss: 0.010946  [24384/60000]\n",
      "loss: 0.093082  [25664/60000]\n",
      "loss: 0.081255  [26944/60000]\n",
      "loss: 0.179682  [28224/60000]\n",
      "loss: 0.057544  [29504/60000]\n",
      "loss: 0.083554  [30784/60000]\n",
      "loss: 0.069916  [32064/60000]\n",
      "loss: 0.040091  [33344/60000]\n",
      "loss: 0.038021  [34624/60000]\n",
      "loss: 0.089179  [35904/60000]\n",
      "loss: 0.053063  [37184/60000]\n",
      "loss: 0.072828  [38464/60000]\n",
      "loss: 0.061181  [39744/60000]\n",
      "loss: 0.041055  [41024/60000]\n",
      "loss: 0.059572  [42304/60000]\n",
      "loss: 0.071527  [43584/60000]\n",
      "loss: 0.100699  [44864/60000]\n",
      "loss: 0.101443  [46144/60000]\n",
      "loss: 0.123036  [47424/60000]\n",
      "loss: 0.027193  [48704/60000]\n",
      "loss: 0.063568  [49984/60000]\n",
      "loss: 0.056444  [51264/60000]\n",
      "loss: 0.066775  [52544/60000]\n",
      "loss: 0.099961  [53824/60000]\n",
      "loss: 0.176702  [55104/60000]\n",
      "loss: 0.107922  [56384/60000]\n",
      "loss: 0.042482  [57664/60000]\n",
      "loss: 0.020259  [58944/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.059672 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.020688  [   64/60000]\n",
      "loss: 0.275196  [ 1344/60000]\n",
      "loss: 0.193051  [ 2624/60000]\n",
      "loss: 0.047221  [ 3904/60000]\n",
      "loss: 0.032249  [ 5184/60000]\n",
      "loss: 0.087240  [ 6464/60000]\n",
      "loss: 0.042124  [ 7744/60000]\n",
      "loss: 0.012816  [ 9024/60000]\n",
      "loss: 0.028570  [10304/60000]\n",
      "loss: 0.067382  [11584/60000]\n",
      "loss: 0.122300  [12864/60000]\n",
      "loss: 0.033070  [14144/60000]\n",
      "loss: 0.037903  [15424/60000]\n",
      "loss: 0.082088  [16704/60000]\n",
      "loss: 0.125264  [17984/60000]\n",
      "loss: 0.065084  [19264/60000]\n",
      "loss: 0.051662  [20544/60000]\n",
      "loss: 0.006421  [21824/60000]\n",
      "loss: 0.124327  [23104/60000]\n",
      "loss: 0.130147  [24384/60000]\n",
      "loss: 0.052409  [25664/60000]\n",
      "loss: 0.034784  [26944/60000]\n",
      "loss: 0.076268  [28224/60000]\n",
      "loss: 0.190560  [29504/60000]\n",
      "loss: 0.126462  [30784/60000]\n",
      "loss: 0.012317  [32064/60000]\n",
      "loss: 0.004533  [33344/60000]\n",
      "loss: 0.053745  [34624/60000]\n",
      "loss: 0.301122  [35904/60000]\n",
      "loss: 0.175053  [37184/60000]\n",
      "loss: 0.022919  [38464/60000]\n",
      "loss: 0.008633  [39744/60000]\n",
      "loss: 0.049870  [41024/60000]\n",
      "loss: 0.065617  [42304/60000]\n",
      "loss: 0.055642  [43584/60000]\n",
      "loss: 0.085654  [44864/60000]\n",
      "loss: 0.023334  [46144/60000]\n",
      "loss: 0.059378  [47424/60000]\n",
      "loss: 0.022012  [48704/60000]\n",
      "loss: 0.026578  [49984/60000]\n",
      "loss: 0.030555  [51264/60000]\n",
      "loss: 0.124828  [52544/60000]\n",
      "loss: 0.037844  [53824/60000]\n",
      "loss: 0.065320  [55104/60000]\n",
      "loss: 0.040092  [56384/60000]\n",
      "loss: 0.062422  [57664/60000]\n",
      "loss: 0.087515  [58944/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.053830 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.028079  [   64/60000]\n",
      "loss: 0.100343  [ 1344/60000]\n",
      "loss: 0.049005  [ 2624/60000]\n",
      "loss: 0.042803  [ 3904/60000]\n",
      "loss: 0.008813  [ 5184/60000]\n",
      "loss: 0.050255  [ 6464/60000]\n",
      "loss: 0.082960  [ 7744/60000]\n",
      "loss: 0.026529  [ 9024/60000]\n",
      "loss: 0.083658  [10304/60000]\n",
      "loss: 0.066665  [11584/60000]\n",
      "loss: 0.018181  [12864/60000]\n",
      "loss: 0.105289  [14144/60000]\n",
      "loss: 0.103314  [15424/60000]\n",
      "loss: 0.088893  [16704/60000]\n",
      "loss: 0.086205  [17984/60000]\n",
      "loss: 0.028351  [19264/60000]\n",
      "loss: 0.082598  [20544/60000]\n",
      "loss: 0.032553  [21824/60000]\n",
      "loss: 0.014682  [23104/60000]\n",
      "loss: 0.016865  [24384/60000]\n",
      "loss: 0.036275  [25664/60000]\n",
      "loss: 0.052352  [26944/60000]\n",
      "loss: 0.029432  [28224/60000]\n",
      "loss: 0.042070  [29504/60000]\n",
      "loss: 0.138253  [30784/60000]\n",
      "loss: 0.166211  [32064/60000]\n",
      "loss: 0.058677  [33344/60000]\n",
      "loss: 0.020240  [34624/60000]\n",
      "loss: 0.072464  [35904/60000]\n",
      "loss: 0.090283  [37184/60000]\n",
      "loss: 0.036163  [38464/60000]\n",
      "loss: 0.017475  [39744/60000]\n",
      "loss: 0.076871  [41024/60000]\n",
      "loss: 0.007014  [42304/60000]\n",
      "loss: 0.054555  [43584/60000]\n",
      "loss: 0.033210  [44864/60000]\n",
      "loss: 0.018430  [46144/60000]\n",
      "loss: 0.115134  [47424/60000]\n",
      "loss: 0.006018  [48704/60000]\n",
      "loss: 0.085415  [49984/60000]\n",
      "loss: 0.037909  [51264/60000]\n",
      "loss: 0.030499  [52544/60000]\n",
      "loss: 0.013627  [53824/60000]\n",
      "loss: 0.170938  [55104/60000]\n",
      "loss: 0.014444  [56384/60000]\n",
      "loss: 0.022141  [57664/60000]\n",
      "loss: 0.034081  [58944/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.043800 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.004847  [   64/60000]\n",
      "loss: 0.067390  [ 1344/60000]\n",
      "loss: 0.026102  [ 2624/60000]\n",
      "loss: 0.029498  [ 3904/60000]\n",
      "loss: 0.053045  [ 5184/60000]\n",
      "loss: 0.028356  [ 6464/60000]\n",
      "loss: 0.044495  [ 7744/60000]\n",
      "loss: 0.012824  [ 9024/60000]\n",
      "loss: 0.044121  [10304/60000]\n",
      "loss: 0.073542  [11584/60000]\n",
      "loss: 0.028369  [12864/60000]\n",
      "loss: 0.022973  [14144/60000]\n",
      "loss: 0.023593  [15424/60000]\n",
      "loss: 0.056746  [16704/60000]\n",
      "loss: 0.010985  [17984/60000]\n",
      "loss: 0.161689  [19264/60000]\n",
      "loss: 0.125730  [20544/60000]\n",
      "loss: 0.005812  [21824/60000]\n",
      "loss: 0.056239  [23104/60000]\n",
      "loss: 0.024651  [24384/60000]\n",
      "loss: 0.016571  [25664/60000]\n",
      "loss: 0.107148  [26944/60000]\n",
      "loss: 0.011014  [28224/60000]\n",
      "loss: 0.005634  [29504/60000]\n",
      "loss: 0.011488  [30784/60000]\n",
      "loss: 0.044447  [32064/60000]\n",
      "loss: 0.037584  [33344/60000]\n",
      "loss: 0.038971  [34624/60000]\n",
      "loss: 0.015564  [35904/60000]\n",
      "loss: 0.057682  [37184/60000]\n",
      "loss: 0.135139  [38464/60000]\n",
      "loss: 0.046983  [39744/60000]\n",
      "loss: 0.035502  [41024/60000]\n",
      "loss: 0.036186  [42304/60000]\n",
      "loss: 0.005120  [43584/60000]\n",
      "loss: 0.013756  [44864/60000]\n",
      "loss: 0.105719  [46144/60000]\n",
      "loss: 0.099140  [47424/60000]\n",
      "loss: 0.011296  [48704/60000]\n",
      "loss: 0.036056  [49984/60000]\n",
      "loss: 0.017662  [51264/60000]\n",
      "loss: 0.048571  [52544/60000]\n",
      "loss: 0.014765  [53824/60000]\n",
      "loss: 0.081430  [55104/60000]\n",
      "loss: 0.037955  [56384/60000]\n",
      "loss: 0.021720  [57664/60000]\n",
      "loss: 0.018362  [58944/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.040179 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    test_loop(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PersonalAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
